------------------------------------------------------
PASOS PARA PROBAR CONSULTAS EN DOCKER
------------------------------------------------------

1. copiar la carpeta docker-compose-flink en un directorio 

2. acceder al directorio docker-compose-flink

3. tener en cuenta que en la configuración de docker-compose.yml, se especifica un
directorio para compartir datos entre el host y el contenedor en docker.
Este directorio está especificado como 
	volumes:
      		- ~/data:/data
donde ~/data es el directorio en el host y /data el directorio en docker
En el directorio ~/data copiar el dataset o los datasets de prueba

3. ejecutar el comando: 
docker-compose up
o
docker-compose up --scale taskmanager=n (donde n es el número de taskmanager)

4. ejecutar el archivo .sh con los siguientes parámetros
- el # de la consulta
- la ruta en el host donde se encuentra el .jar que se va a ejecutar
- la ruta del volumen compartido entre el host y el contenedor en docker (ver paso 3)
- la ruta al dataset en el contenedor en docker (ver final del paso 3)
Ejemplo: 
./run-test.sh 1 ~/sparql2flink-test/query-1.0-SNAPSHOT.jar /data /data/dataset.nt

No es necesario especificar la clase dentro del .jar que se va a ejecutar, por defecto se ejecuta
org.univalle.rdf.out.Query

5. El archivo .sh genera un archivo con nombre query-time.txt donde se almacena el tiempo de cada
consulta. Este archivo se encontrará en la carpeta desde donde se ejecutó el .sh
El tiempo de la consulta no incluye el tiempo de carga del dataset, ni tampoco el tiempo de creación
de creación del archivo con el resultado de la consulta.


NOTA: se asume que docker-compose ya está levantado.





